{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYySemC6U_MQ"
      },
      "source": [
        "# Deep Learning 101\n",
        "\n",
        "**Goal of the Practical:**\n",
        "The goal of this practical is to provide hands-on experience in building neural networks using PyTorch and training them on the California Housing Dataset. You will learn how to design, implement, and optimize neural networks for regression tasks, specifically predicting housing prices. This practical will guide you through the process of creating a basic model and iteratively improving its performance by exploring different architectures, optimizers, and activation functions.\n",
        "\n",
        "**Dataset Overview:**\n",
        "The California Housing Dataset is a dataset used for regression tasks, originally published in the paper \"Sparse Spatial Autoregressions\" by Pace, R. Kelley and Ronald Barry. It contains information on various attributes of houses in California, such as the median income, median house value, median age, total rooms, total bedrooms, population, households, latitude, and longitude. The goal is to predict the median house value based on these features. This dataset is well-suited for evaluating and comparing different regression algorithms and techniques in the context of housing price prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "ou6KtXLCDcHi"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "2vus61diRwFb"
      },
      "outputs": [],
      "source": [
        "data = fetch_california_housing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "IMokchx9Dle8"
      },
      "outputs": [],
      "source": [
        "X_data = data['data']\n",
        "y_data = data['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make some data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ0B_dhKEj2U"
      },
      "source": [
        "Split the dataset between train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEfckMYlWOVb"
      },
      "source": [
        "Practical Steps:\n",
        "\n",
        "Data Preparation:\n",
        "\n",
        "Preprocess the data by normalizing the numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQNJtYwHbXfb"
      },
      "source": [
        "Building a Basic Model:\n",
        "\n",
        "Create a basic neural network model using PyTorch with a single hidden layer.\n",
        "Define the input layer size based on the number of features in the dataset\n",
        "\n",
        "Choose an appropriate activation function for the hidden layer (e.g., ReLU).\n",
        "Set the output layer size to 1 since it is a regression task.\n",
        "Compile the model with a suitable loss function (e.g., pairwise ranking loss or listwise ranking loss) and optimizer (e.g., Adam)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoZKZ-5Ekfvr"
      },
      "source": [
        "Use: `nn.Linear` and `nn.ReLU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWhNrtXaMJBa"
      },
      "source": [
        "Do not forget this is a regression problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use xavier_uniform_ to init the weights of the linear layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "LLUpvY03bUo3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "oFAN7TNVkpRk"
      },
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, nb_features: int, hidden_size: int):\n",
        "        # FIXME\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # FIXME\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "wCq5LPXgm111"
      },
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "id": "Wwi1d9wfFuPO"
      },
      "outputs": [],
      "source": [
        "# You can use this function to count the number of parameters of your model\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR1VJeVKba1Q"
      },
      "source": [
        "Training and Evaluation:\n",
        "\n",
        "Train the basic model on the training set and evaluate its performance on the validation set.\n",
        "Monitor the training loss and validation metrics to assess the model's learning progress.\n",
        "Adjust the number of epochs, batch size, and learning rate to find the optimal configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxrJjNpvb0tV"
      },
      "source": [
        "Measure the performances of the model using MSE loss, L1 loss and R2 score\n",
        "\n",
        "Plot at the end all the score for each epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check on the internet how to build a training / eval loop. You don't need to use torch Dataset and DataLoader we can just extract batch from tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "id": "IZ6QqrOr9hAB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the training / test loss (MSE Loss / L1 Loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now plot the R2 score for train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Gqya3Tbdrk"
      },
      "source": [
        "Improving the Model:\n",
        "\n",
        "Experiment with adding multiple hidden layers to the neural network.\n",
        "Vary the number of neurons in each hidden layer and observe the impact on performance.\n",
        "Try different activation functions (e.g., Sigmoid, Tanh) and compare their effects.\n",
        "Explore different optimizers (e.g., SGD, RMSprop) and learning rate schedules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI0u_JfBbd6e"
      },
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SroBz_NbmwS"
      },
      "source": [
        "Hyperparameter Tuning:\n",
        "\n",
        "Perform a grid search or random search to find the best combination of hyperparameters.\n",
        "Evaluate the model's performance using cross-validation to ensure robustness.\n",
        "Select the best-performing model based on the validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abIuL_DvbnqV"
      },
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
