{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Conv\n",
        "\n",
        "In the \"Advanced Convolutional Networks\" practical, we'll embark on a hands-on journey to implement foundational models that have shaped the landscape of deep learning. Starting with LeNet, the pioneer of convolutional networks, we'll delve into the architecture that began it all. Then, we'll tackle the Inception network, known for its innovative use of parallel convolutional paths to increase depth and width without the cost of computational complexity. Finally, we'll explore the Residual Block (ResBlock) concept, central to ResNet architectures, which introduced skip connections to enable the training of substantially deeper networks. This practical offers a unique opportunity to build these models from scratch, understanding the mechanics and innovations that drive their success."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wXz-GoMvwN6H"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqzg4d4uwmel",
        "outputId": "8ef48a03-375a-4f45-af59-cd31f4f993e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ68G5Hyymgj"
      },
      "source": [
        "For your practical, you will be adapting the structure of the famous LeNet architecture to create a modified version. Hereâ€™s what your model should include:\n",
        "\n",
        "- Start with a convolutional layer. This layer should have 32 output channels and use a 5x5 kernel. Follow this with a ReLU activation function.\n",
        "\n",
        "- Apply a max pooling layer with a 2x2 kernel to reduce the spatial dimensions.\n",
        "Add another convolutional layer, this time with 64 output channels and a 5x5 kernel, again followed by a ReLU activation function.\n",
        "\n",
        "- Use a max pooling layer with a 2x2 kernel, similar to step 2.\n",
        "Incorporate a third convolutional layer with 64 output channels and a 5x5 kernel, followed by a ReLU activation function.\n",
        "\n",
        "- Follow this with a max pooling layer using a 2x2 kernel, as in steps 2 and 4.\n",
        "Flatten the output from the previous layers to prepare it for the fully connected layers.\n",
        "\n",
        "- Add a fully connected (dense) layer with 1000 output neurons, combined with a ReLU activation function.\n",
        "\n",
        "- Conclude with a fully connected layer that has 10 output neurons.\n",
        "An important note for your assignment: Ensure the spatial dimensions are preserved after each convolutional layer. This will require careful selection of padding and stride parameters.\n",
        "\n",
        "The input images for your model will have the shape (3, 32, 32), indicating 3 color channels with 32x32 pixel resolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seStbKm-woMD"
      },
      "outputs": [],
      "source": [
        "class CustomLeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()  # Important, otherwise will throw an error\n",
        "\n",
        "    # FIXME\n",
        "\n",
        "  def forward(self, x):\n",
        "    # FIXME\n",
        "    return x\n",
        "\n",
        "\n",
        "net = CustomLeNet()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-pbocNozpsN"
      },
      "source": [
        "Make a small test with random data. Make the inference of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5RYPkG_z2et"
      },
      "source": [
        "You can use the following code, to download CIFAR10. Update the code to transform the images to tensor and to normalize the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_xfAIzzzxAQ",
        "outputId": "e8687ca3-2127-46fe-b431-c22a9e3d49ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_mean = torch.tensor([0.5071, 0.4867, 0.4408])\n",
        "cifar_std = torch.tensor([0.2675, 0.2565, 0.2761])\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    # FIXME\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    # FIXME\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = CIFAR10(\"/tmp\", download=True, train=True, transform=train_transforms)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    train_dataset,\n",
        "    [int(0.8 * len(train_dataset)), int(0.2 * len(train_dataset))]\n",
        "  )\n",
        "\n",
        "val_dataset.transform = test_transforms\n",
        "test_dataset = CIFAR10(\"/tmp\", download=False, train=False, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulXeQA0Z0RAV"
      },
      "source": [
        "Display the number of images in the train / val / test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBW1wckj0Van"
      },
      "source": [
        "Build the dataloader and display the number of batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67vWticd0ryY"
      },
      "source": [
        "Now display some images with the associated classes from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MYFyTebD0wJQ"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    'plane',\n",
        "    'car',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2cblJth2R1k"
      },
      "source": [
        "Now build a function that will be used to evaluate the model\n",
        "\n",
        "- Loop into the dataloader\n",
        "- Make the inference of the model\n",
        "- Compute the loss function\n",
        "- Compute the argmax of the prediction logits\n",
        "- Then compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZQUgU7X2jrv"
      },
      "source": [
        "Now:\n",
        "\n",
        "- Send you model on the device.\n",
        "\n",
        "- Build the SGD Optimizer\n",
        "\n",
        "- Use the cross entropy loss\n",
        "\n",
        "- Build the training loops\n",
        "\n",
        "do not forget to keep train / val accuracy and loss for each epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh5Gt2tL6UxE"
      },
      "source": [
        "Plot the train and val accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBYbT7tf6jis"
      },
      "source": [
        "Eval the model now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX8i0Mys6ry1"
      },
      "source": [
        "Your goal is to determine the specific contributions of each enhancement to the model's performance. Here's how you should proceed:\n",
        "\n",
        "- Data Augmentation: Start by enriching the training data with more varied examples. This can include applying mirror flips, random crops, and color jittering to the input images. The aim is to make your model more robust to variations in the input data.\n",
        "\n",
        "- Regularization: Incorporate techniques like dropout or weight decay to prevent the model from overfitting. Overfitting happens when a model learns the training data too well, including its noise, which hurts its performance on unseen data.\n",
        "\n",
        "- Improved Architecture: Integrate Batch Normalization into your model. Batch Normalization can accelerate training, in part by reducing internal covariate shift. This involves normalizing the input of each layer in a way that maintains the mean output close to 0 and the output standard deviation close to 1.\n",
        "\n",
        "- Optimization Techniques: Experiment with advanced optimization strategies. Consider using different learning rates, momentum (including the possibility of Nesterov momentum), and adaptive learning rate methods like RMSProp or Adam.\n",
        "\n",
        "\n",
        "These techniques can help in finding better minima faster and more reliably than standard gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSdHtbKt7j44"
      },
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLXrHcDe7DVx"
      },
      "source": [
        "You've successfully implemented a modified version of LeNet, a pioneering convolutional neural network by Yann Le Cun. While impressive for its time, today's demands call for more sophisticated models.\n",
        "\n",
        "Moving forward, we'll explore advanced techniques that have significantly boosted neural network performance since the era of AlexNet. These improvements encompass data augmentation, regularization, architectural enhancements, and optimization strategies.\n",
        "\n",
        "Our next step is to create a versatile convolution block. This block will include a convolutional layer, followed by batch normalization, and conclude with a ReLU activation function. This will serve as a foundational component for building more complex and efficient networks. As a practice, try implementing and training these enhanced models on datasets like CIFAR10 to see their full potential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFPO3Kwo6jDH"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n",
        "    super().__init__()\n",
        "    # TODO\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08mYTVry-uQE"
      },
      "source": [
        "Now we are going to make the implementation of inception\n",
        "\n",
        "Paper: https://arxiv.org/pdf/1409.4842.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9P30vJ6F78wX"
      },
      "outputs": [],
      "source": [
        "class InceptionBlock(nn.Module):\n",
        "  def __init__(self, in_channels, reduced_channels, out_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    # TODO\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsTT0fBBA0el"
      },
      "source": [
        "Inception full implementation:\n",
        "\n",
        "https://github.com/pytorch/vision/blob/main/torchvision/models/inception.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZrF0dse_NKc"
      },
      "source": [
        "Now we are going to implement a ResNet block\n",
        "\n",
        "Paper: https://arxiv.org/pdf/1512.03385.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "N_5Kw9-s_MsK"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, input_channels, hidden_channels):\n",
        "    super().__init__()\n",
        "    # Use a kernel size of 3\n",
        "\n",
        "    # FIXME\n",
        "\n",
        "  def forward(self, x):\n",
        "    # FIXME\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYgQqjiuCEje"
      },
      "source": [
        "ResNet implem: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7fnC-ECKcx"
      },
      "source": [
        "To go further, read the following papers, implement them, and try to run them on a small dataset like CIFAR.\n",
        "\n",
        "Here is a non-exhaustive list:\n",
        "\n",
        "- MobileNet: https://arxiv.org/abs/1704.04861\n",
        "- ShuffleNet: https://arxiv.org/abs/1707.01083\n",
        "- SEnet: https://arxiv.org/abs/1709.01507\n",
        "- DenseNet: https://arxiv.org/abs/1608.06993\n",
        "- ResNext: https://arxiv.org/abs/1611.05431\n",
        "- EfficientNet: https://arxiv.org/abs/1905.11946"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d82Ll99iBLxh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
