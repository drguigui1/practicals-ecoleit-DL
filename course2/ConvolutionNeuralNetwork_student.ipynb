{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLyZwjh37ZKs"
      },
      "source": [
        "# Convolution Neural Network\n",
        "\n",
        "Throughout this practical, you will follow a series of steps to gain a deep understanding of CNNs and their applications. These steps include:\n",
        "\n",
        "Loading and preprocessing the CIFAR-10 dataset using PyTorch's data transformations. The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. Splitting the dataset into train and validation sets to evaluate the performance of your models. Building a simple CNN architecture from scratch, experimenting with various layers, and exploring the effects of adding batch normalization and dropout. Developing a more advanced CNN model, ResNet, from scratch, and understanding its unique residual connections that enable the training of deeper networks. Training and evaluating your ResNet model on the CIFAR-10 dataset, and comparing its performance to the simpler CNN architectures.\n",
        "\n",
        "By the end of this practical, you will have gained valuable experience in building and training CNNs for image classification tasks, as well as an understanding of the importance of residual connections in deep neural networks. Let's dive into the world of CNNs and discover their potential for solving complex visual recognition tasks using the CIFAR-10 dataset!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QClyLzKrE86",
        "outputId": "2a078b6a-0673-4d08-97a0-cbc0993f6633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar 10 18:42:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cN6MmENu605_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhljVsnK-qs7"
      },
      "source": [
        "In this part of the practical, you are required to define a sequence of transformations for the CIFAR-10 dataset using PyTorch's transforms.Compose function. The purpose of these transformations is to preprocess and augment the input images before feeding them into the Convolutional Neural Network (CNN). The provided code block accomplishes this as follows:\n",
        "\n",
        "Random Horizontal Flip: Apply the transforms.RandomHorizontalFlip transformation with a probability of 0.5. This means that there is a 50% chance that each image will be flipped horizontally. Horizontal flipping is a common data augmentation technique that helps the CNN learn to recognize objects regardless of their orientation, increasing the model's robustness and generalization ability.\n",
        "\n",
        "Random Rotation: Use the transforms.RandomRotation transformation to randomly rotate the images within a specified range of degrees, in this case, between -15 and 15 degrees. Random rotation is another data augmentation technique that helps the CNN learn to be invariant to slight rotations in the input images. By exposing the model to a variety of rotated images during training, it becomes more resilient to rotational variations in real-world scenarios.\n",
        "\n",
        "Convert the images to tensors: Apply the transforms.ToTensor transformation to convert each image from PIL Image format to a PyTorch tensor. This step is necessary because CNNs operate on tensors rather than raw image data. The ToTensor transformation automatically scales the pixel values from the range [0, 255] to [0, 1].\n",
        "\n",
        "By applying these transformations, you are effectively preprocessing and augmenting the CIFAR-10 dataset before passing it to the CNN. Data augmentation techniques like random horizontal flipping and random rotation help increase the diversity of the training data, reducing overfitting and improving the model's ability to generalize to unseen examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "-iu4ieZU7NxQ"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    # FIXME\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojY6Tmx_AA6W"
      },
      "source": [
        "Now load the dataset by using `torchvision.datasets.CIFAR10`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCN8I2859L6U",
        "outputId": "c6ee7178-bbcd-411b-ac88-7e9733eb11d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dataset = torchvision.datasets.CIFAR10(root=\"train_data/\", transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8silOwqBcST"
      },
      "source": [
        "Display the type of the torchvision.datasets.CIFAR10 you have loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCsnhw0HDAwI"
      },
      "source": [
        "Display the number of samples for train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQxexncRBhyh"
      },
      "source": [
        "Get the first element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhMQoRXHBl45"
      },
      "source": [
        "Display the shape of the first element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVi1zgSUB2jG"
      },
      "source": [
        "Now display some images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Tld31xCOdP"
      },
      "source": [
        "Display the list of classes `dataset.classes`\n",
        "And display the number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEcIrOyEEqzX"
      },
      "source": [
        "Split the dataset between train and validation\n",
        "\n",
        "You can do this with `SubsetRandomSampler` and then directly build your dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "mMaWvUAIFiy5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "FqeEVkU2F6SJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INP_o9sbF9fQ"
      },
      "source": [
        "Now you have your dataloader extract the first batch of your dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ryDIit2IuDH"
      },
      "source": [
        "Import the necessary PyTorch modules for building the CNN architecture.\n",
        "\n",
        "Create a custom CNN class that inherits from PyTorch's nn.Module.\n",
        "\n",
        "Define the constructor method for your custom CNN class, accepting the number of classes as an argument.\n",
        "\n",
        "Initialize convolutional layers, max-pooling layers, fully connected (linear) layers, and dropout layers within the constructor.\n",
        "\n",
        "Implement the forward method in your custom CNN class to pass the input tensor through the defined layers.\n",
        "\n",
        "Flatten the output tensor from the convolutional and pooling layers before passing it to the fully connected layers.\n",
        "\n",
        "Return the output tensor from the final fully connected layer in the forward method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5125X-jJgFt"
      },
      "source": [
        "Make the inference of the model with random batch data to verify everything works properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "AW2mdg9OLbEr"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDsKHELlL7Id"
      },
      "source": [
        "Build the loss function and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRpJ_X6nJddG"
      },
      "source": [
        "Now build the training and validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "gM3zrUSCLlR_"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQTcqtWLPp1M"
      },
      "source": [
        "Play with the architecture of the model and the hyperparameters.\n",
        "\n",
        "And implement from scratch ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzIAfNk8Pw8F"
      },
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
